{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are going to obtain our football dataset, delete the irrelevant features, and normalize it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we will get our data from FBREF. To do that, we generate a csv for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_csv(url: str, csv_name: str, stats_to_drop: List[str]=['Rk', 'Born', 'Matches', '90s', 'Nation', 'Pos', 'Squad', 'Comp', 'Age']) -> None:\n",
    "    data = pd.read_html(url, header=1)[0]\n",
    "\n",
    "    #keep=False is to delete also the first one.\n",
    "    data.drop_duplicates(subset=['Rk'], keep=False, inplace=True) \n",
    "\n",
    "    #Drop the players that during the season changed teams, meaning they appear twice with the same stats.\n",
    "    data.drop_duplicates(subset=['Player'], inplace=True)\n",
    "\n",
    "    data.drop(columns=stats_to_drop, inplace=True)\n",
    "\n",
    "    data.set_index(['Player'], inplace=True)\n",
    "\n",
    "    data.to_csv(csv_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://fbref.com/en/comps/Big5/2022-2023/{category}/players/2022-2023-Big-5-European-Leagues-Stats'\n",
    "\n",
    "categories = [('shooting', 'shooting.csv'), ('passing', 'passing.csv'), ('passing_types', 'passtypes.csv'),\n",
    "            ('gca', 'gca.csv'), ('defense', 'def.csv'), ('possession', 'pos.csv'), ('misc', 'mis.csv')]\n",
    "\n",
    "generate_csv('https://fbref.com/en/comps/Big5/2022-2023/stats/players/2022-2023-Big-5-European-Leagues-Stats', 'std.csv', ['Rk', 'Born','Matches','90s'])\n",
    "\n",
    "for i in categories:\n",
    "    completed_url = url.format(category=i[0])\n",
    "\n",
    "    generate_csv(completed_url, i[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then, we merge the csvs into one that contains all the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_csvs(csv_left: str, csv_right: str) -> str:\n",
    "    left = pd.read_csv(csv_left)\n",
    "    right = pd.read_csv(csv_right)\n",
    "\n",
    "    # Since some different stats have the same names, we need to add suffixes to differentiate them.\n",
    "    data = left.merge(right, left_on='Player', right_on='Player', suffixes=(f'_{csv_left[:-4]}',f'_{csv_right[:-4]}')) \n",
    "\n",
    "    data.set_index(['Player'], inplace=True)\n",
    "\n",
    "    output_name = f'{csv_left[:-4]}_{csv_right[:-4]}.csv'\n",
    "\n",
    "    data.to_csv(output_name)\n",
    "\n",
    "    return output_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_names = ['std.csv', 'shooting.csv', 'passing.csv', 'passtypes.csv', 'gca.csv', 'def.csv', 'pos.csv', 'mis.csv']\n",
    "\n",
    "merged_file = csv_names[0]\n",
    "for new_csv in csv_names[1:]:\n",
    "    merged_file = merge_csvs(merged_file, new_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By looking at the merged csv, we notice that there are many stats that are repeated or irrelevant. We now delete them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_drop(csv_name: str, stats: List[str]) -> None:\n",
    "    data = pd.read_csv(csv_name)\n",
    "\n",
    "    data.drop(stats, inplace=True, axis=1) \n",
    "\n",
    "    data.set_index(['Player'], inplace=True)\n",
    "\n",
    "    data.to_csv('Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_to_drop = ['Gls.1', 'Ast.1', 'G+A.1', 'G-PK.1', 'G+A-PK', 'xG.1', 'xAG.1', 'xG+xAG', 'npxG.1' ,'npxG+xAG.1',\n",
    "                'Gls_shooting', 'Sh/90',\t'SoT/90','PK_shooting',\t'PKatt_shooting',\t'xG_shooting',\t'npxG_shooting',\n",
    "                'Ast_passing',\t'xAG_passing', 'PrgP_passing',\n",
    "                'Att_passtypes','Cmp_passtypes',\n",
    "                'SCA90', 'GCA90',\n",
    "                'PrgC_pos','PrgR_pos',\n",
    "                'CrdY_mis','CrdR_mis','Crs_mis','Int_mis','TklW_mis',\n",
    "                'Cmp%','Cmp%.1','Cmp%.2','Cmp%.3','Tkl%','Succ%','Tkld%','Won%','SoT%']\n",
    "\n",
    "columns_drop('std_shooting_passing_passtypes_gca_def_pos_mis.csv', stats_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, we normalize our data using Z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(csv_name: str) -> None:\n",
    "\n",
    "    data = pd.read_csv(csv_name)\n",
    "\n",
    "    #Divide by number of minutes\n",
    "    data.iloc[:, 9:] = data.iloc[:, 9:].div(data['Min'], axis=0)\n",
    "\n",
    "    #Z-score\n",
    "    data.iloc[:, 9:] = (data.iloc[:, 9:]-data.iloc[:, 9:].mean()) / data.iloc[:, 9:].std()\n",
    "\n",
    "    data.set_index(['Player'], inplace=True)\n",
    "\n",
    "    data.to_csv('Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize('Final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We perform a couple of basic tests besides manually looking at the csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4208177921845034e-17\n",
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Final.csv')\n",
    "\n",
    "print(data['Tkld'].mean())\n",
    "print(data['Sh'].std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
